<image src="https://uk-alliance.org/wp-content/uploads/2022/01/wb.png" alt="Иллюстрация к проекту" width="800" height="300">

# **Проект по Анализу Данных**
## Тема проекта: "Парсинг сайта "Wildberries", раздел "Книги по психологии".  Выполнили: Миропольская Анна Романовна и Савенкова Софья Дмитриевна, группа БЭК215

### Шаг 1: выбор темы
На данном этапе перед нами стояла задача выбора темы. Мы остановили свой выбор на книгах по психологии, так как мы достаточно увлечены данной наукой и являемся частыми покупателями соответствующей литературы. Также важным фактором является то, что платформа "Wildberries" на данный момет ялвяется одним из крупнейших интернет-магазинов в России.

### Шаг 2: сбор данных
На втором этапе нами был произведен парсинг датасета с сайта "Wildberries", раздел "Книги по психологии". В качестве характеристик мы взяли название, цена, рейтинг, отзывы, длина книги бла бла бла.
Для парсинга мы импортировали необходимые библиотеки и модули: time для работы с временем; sleep из модуля time для приостановки выполнения программы на определенное количество секунд; selenium для автоматизации веб-браузера; Service из модуля selenium.webdriver.chrome.service для создания сервиса Chrome WebDriver; BeautifulSoup из модуля bs4 для разбора HTML-кода; pandas для работы с данными в формате таблицы; requests для выполнения HTTP-запросов; csv для работы с CSV-файлами.. Они будут использоваться нами для работы с временными задержками, автоматизации браузера, парсинга HTML, обработки данных и отправки запросов.

Пошаговое объяснение нашего кода.
1. Для начала мы задаем необходимые заголовки для HTTP-запросов в переменной headers, они будут использоваться при отправке запросов на сайт.
2. Далее мы создаем пустой список urls, в который будут далее добавляться ссылки на книги.
3. Создаем цикл for для переменной p в диапазоне от 1 до 60. 
В каждой итерации цикла формируется URL-адрес страницы с книгами на сайте Wildberries. Параметры сортировки и номер страницы вставляются в URL с помощью форматирования строк. 
4. На следующем шаге мы создаем экземпляр сервиса Service с указанием пути к драйверу Chrome. Затем создаем объект browser с использованием драйвера Chrome и у нас открывается URL-адрес, полученный в предыдущем шаге.
5. Создаем пустой список books_divs, в который будем добавлять элементы книг на странице.
6. Выполняем вложенный цикл for для переменной i в диапазоне от 0 до 10. В каждой итерации цикла выполняются следующие действия:
7. Выполняется скрипт JavaScript для прокрутки страницы вниз до конца с помощью метода execute_script браузера. Это нужно для загрузки дополнительных элементов на страницу.
8. Выполняется задержка в 1 секунду с помощью функции sleep из модуля time.
9. Получается исходный код страницы с помощью метода page_source браузера.
10. Далее используем BeautifulSoup для создания объекта soup и парсинга HTML-кода страницы.
11. Извлекаем все элементы книг с помощью метода find_all объекта soup и сохраняем в переменную books_divs.
12. Выполняем цикл for для переменной book в списке books_divs. В каждой итерации цикла извлекается ссылка на книгу с помощью метода find и сохраняем в переменную url. Затем ссылка добавляется в список urls.
13. Открывается файл "urls.csv" в режиме записи с помощью функции open. Задаем настройки для файла, включая использование символа новой строки \n и кодировку "utf-8". Создается объект writer с использованием модуля csv, который позволяет записывать данные в CSV-файлы.
14. Выполняется цикл for для переменной url в списке urls. В каждой итерации цикла записывается ссылка на книгу в CSV-файл с помощью метода writerow объекта writer.
  Таким образом, в результате выполнения кода будут собраны ссылки на книги со страниц Wildberries и записаны в файл "urls.csv". Каждая ссылка будет записана в отдельной строке CSV-файла.


Данный мы выполняем следующее:
1. Создается пустой список `urls`, который будет использоваться для хранения ссылок на книги.
2. Открывается файл `urls.csv` в режиме чтения (`'r'`). Создается объект `reader` из модуля `csv.reader` для чтения данных из CSV-файла.
3. В цикле `for row in reader` каждая строка из файла `urls.csv` обрабатывается отдельно. Вложенный цикл `for row in reader` используется для проверки каждой строки внутри файла.
4. Проверяется, что строка не пустая с помощью условного оператора `if row`. Если строка не пустая, то извлекается первый элемент `row[0]`, который предполагается, что это ссылка на книгу, и добавляется в список `urls`.
5. Открывается файл `final.csv` в режиме добавления (`'a'`). Создается объект `writer` из модуля `csv.writer` для записи данных в CSV-файл.
6. В цикле `for index, url in enumerate(urls, start=1)` проходятся все ссылки в списке `urls` с использованием функции `enumerate`. Каждая ссылка имеет соответствующий индекс, начиная с 1.
7. Создается список `data`, который содержит индекс и ссылку на книгу.
8. Браузер открывает страницу с соответствующей ссылкой `browser.get(url)`.
9. Используется метод `execute_script` браузера для прокрутки страницы до ее нижней части, чтобы загрузить дополнительные данные.
10. Выполняется пауза в 2 секунды с помощью функции `time.sleep(2)` для ожидания загрузки данных.
11. Попытка найти название книги на странице с помощью метода `find_element` и XPath-выражения `By.XPATH`. Если название книги найдено, оно добавляется в список `data`. В противном случае добавляется значение `'None'`.
12. Аналогично пункту 11 попытки находятся цена книги, количество отзывов и рейтинг книги. Если соответствующие данные найдены, они добавляются в список `data`. В противном случае добавляется значение `'None'`.
13. Строка `writer.writerow(data)` записывает список `data` в CSV-файл.
14. Закрывается файл.
Код выполняет парсинг информации о книгах со страниц, указанных в файле `urls.csv`, и записывает полученные данные в файл `final.csv`.


  
### Шаг 3: Предварительныя обработка и анализ 
На третьем шаге нам было необходимо обработать и проанализировать выводимые характеристики.
Всего выводимых характеристик получилось 6:
1) Название книги
2) Издательство
3) Цена до скидки
4) Цена после скидки
5) Размер скидки
6) Длина книги
  

### Шаг 4. Визуализация
На этапе визуализации мы решили, что наиболее подходящими вариантами для наших данных будут.



